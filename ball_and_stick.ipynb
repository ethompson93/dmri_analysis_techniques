{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethompson93/dmri_analysis_techniques/blob/main/ball_and_stick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liA9crKKaSXH"
      },
      "source": [
        "# **Compartment models: ball and stick**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btB-dYWMaWOP"
      },
      "source": [
        "In this coding assignment, we will be fitting a simple compartment model to the data: the ball and stick model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L55UQFYAxAiv"
      },
      "source": [
        "Using the same phantom data as the previous exercise, download from https://drive.google.com/drive/folders/12hHKJoAXDB-AsNTzxXf4ZvSbfq-_7qmX?usp=share_link and upload it to this Google collab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Inax-6RayPC"
      },
      "source": [
        "## Loading Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQWY2zBEa1r-"
      },
      "source": [
        "We'll re-use the code from the previous exercise to load in the data and extract the relevant variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGNdOIPDcYNW"
      },
      "outputs": [],
      "source": [
        "## Import libaries\n",
        "import nibabel as nb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import least_squares\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAL5uX5jcm13"
      },
      "outputs": [],
      "source": [
        "## Nifti Images\n",
        "\n",
        "# Load our nifti image as \"dwi_img\" and get data to \"dwi\"\n",
        "dwi_img = nb.load('fibrecup.nii.gz')\n",
        "dwi = dwi_img.get_fdata()\n",
        "\n",
        "# repeat this with the white matter mask\n",
        "mask_img = nb.load('wm_mask.nii.gz')\n",
        "mask = mask_img.get_fdata()\n",
        "\n",
        "## Gradient information\n",
        "# Load our gradient text file at grad\n",
        "grad = np.loadtxt('grad.txt')\n",
        "\n",
        "# select our gradient direction as \"g\"\n",
        "g = grad[:,0:3]\n",
        "\n",
        "# select our b-values as \"b\"\n",
        "b = grad[:,3]\n",
        "\n",
        "## Reshaping\n",
        "# find the index of the voxels within the white matter mask\n",
        "idx = np.where(mask>0)\n",
        "print(np.shape(idx))\n",
        "\n",
        "# extract dwi values at these WM voxels to produce a matrix of\n",
        "# [WM voxels x grad-dirs]. Save this as \"dwi_wm\"\n",
        "dwi_wm = dwi[idx[0],idx[1],idx[2]]\n",
        "\n",
        "## Extracting b0 & non-b0 diffusion signals\n",
        "# find from gradients where the b-value is equal to zero as \"b0idx\"\n",
        "b0idx = np.where(b==0)[0]\n",
        "\n",
        "# find from gradients where the b-value is NOT equal to zero as \"non_b0idx\"\n",
        "non_b0idx = np.where(b!=0)[0]\n",
        "\n",
        "# Extract baseline signal (\"S0\") by indexing \"dwi\" at b0idx\n",
        "S0 = dwi_wm[:,b0idx]\n",
        "\n",
        "# Extract gradient weighted signal (\"S\") by indexing the \"dwi\" at non-b0 values\n",
        "S = dwi_wm[:,non_b0idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This produces four variables (shape of each variable in brackets) which we will need later on:\n",
        "\n",
        "dwi - a 4D (64, 64, 3, 65) numpy array containing the value of diffusion at each voxel of the 3D image for each diffusion direction (65 directions).\n",
        "\n",
        "mask - a 3D (64,64,3) binary array which provides a mask of the voxels corresponding to the brain. a value of 1 i given for each brain voxel, 0 for background.\n",
        "\n",
        "g - gradient directions. A matrix (65,3) containing the direction vector for each diffusion direction.\n",
        "\n",
        "b - corresponding b-values (65,) for each of these gradient directions (comment on whether this is single or multi-shell data)"
      ],
      "metadata": {
        "id": "Z-4a5HqkSMlj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_BabHvwecEQ"
      },
      "source": [
        "# Visualising the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrdhBvPG3Bwo"
      },
      "outputs": [],
      "source": [
        "# make a figure with three subplots for b=0, b=2000 and the wm mask\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axs[0].imshow(dwi[:,:,1,0].T, origin=\"lower\")\n",
        "axs[0].set_title(\"b=0\")\n",
        "axs[1].imshow(np.mean(dwi[:,:,1,1:], axis=2).T, origin=\"lower\")\n",
        "axs[1].set_title(\"average b=2000\")\n",
        "axs[2].imshow(mask[:,:,1].T, origin=\"lower\")\n",
        "axs[2].set_title(\"white matter mask\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zwGvrfS_QKs"
      },
      "source": [
        "## Ball-and-stick model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ball-and-stick model represents the dMRI signal as a weighted sum of contributions from an isotropic \"ball\" compartment, representing the free water in the voxel, and a fibre compartment (the \"stick\"):\n",
        "\n",
        "$S_k=S(0)\\left[(1- f) \\exp (-b_k d)+ f \\exp \\left(-b_k d\\left(\\mathbf{g_k} \\cdot \\mathbf{v}\\right)^2\\right)\\right]$\n",
        "\n",
        "$S_k$ is the signal acquired with b-value $b_k$ and gradient direction $\\mathbf{g_k}$. $f$ is the volume fraction of the fibre compartment, which has an orientation  described by unit vector $\\mathbf{v}$. We assume the same diffusivity constant $d$ for both compartments."
      ],
      "metadata": {
        "id": "4CDfR94jzVxe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mmTaaS2X84E"
      },
      "source": [
        "**Coding Task:** create function \"ball_and_stick\" to generate the expected diffusion signal from the ball and stick model.\n",
        "\n",
        "The function should return the voxel-wise signal for a set of acquisition parameters.\n",
        "\n",
        "Use the following parameters as inputs :\n",
        "\n",
        "*   angles describing the orientation of the stick: `theta` and `phi`\n",
        "  (check out the [wikipedia page](https://en.wikipedia.org/wiki/Spherical_coordinate_system) on spherical coordinates for a refresher on how these relate to the x-y-z coordinates). These will be single float values for each voxel.\n",
        "*   volume fraction of the stick component: `f`. A single float value for each voxel between 0 and 1.\n",
        "*   diffusivity constant: `d`. We fix the value of `d` across all voxels and compartments.\n",
        "*   baseline signal when b = 0: `S0`. Single value for the voxel (,1)\n",
        "*   b-value of diffusion gradient: `b` (N,)\n",
        "*   numpy array describing diffusion encoding gradients: `g` (N,3)\n",
        "\n",
        "Your output should be a vector of size (N,) containing the simulated signal from the ball and stick model for each diffusion weighted direction.\n",
        "\n",
        "N is the number of diffusion acquisitions, in this case 64.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBpQi42sZJEd"
      },
      "outputs": [],
      "source": [
        "def ball(b, d):\n",
        "  pass\n",
        "\n",
        "def stick(b, g, d, theta, phi):\n",
        "  pass\n",
        "\n",
        "def ball_and_stick(theta, phi, f, d, S0, b, g):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nI0MEEPpe1XT"
      },
      "outputs": [],
      "source": [
        "#@title ANSWERS\n",
        "\n",
        "def ball(b, d):\n",
        "  return np.exp(-b*d)\n",
        "\n",
        "# long version\n",
        "def stick(b, g, d, theta, phi):\n",
        "  v = np.array([np.sin(theta)*np.cos(phi), np.sin(theta)*np.sin(phi), np.cos(theta)])\n",
        "  N = len(b) # number of gradient directions\n",
        "  result = np.zeros(N)  # Initialize result array\n",
        "  # iterate through the gradients\n",
        "  for i in range(N):\n",
        "    result[i] = np.exp(-b[i] * d * (np.dot(v, g[i, :])**2))\n",
        "  return result\n",
        "\n",
        "# short version\n",
        "def stick(b, g, d, theta, phi):\n",
        "  v = np.array([np.sin(theta)*np.cos(phi), np.sin(theta)*np.sin(phi), np.cos(theta)])\n",
        "  result = np.exp(-b * d * (np.dot(v, g.T)**2))\n",
        "  return result\n",
        "\n",
        "\n",
        "def ball_and_stick(theta, phi, f, d, S0, b, g):\n",
        "  isotropic_signal = ball(b,d)\n",
        "  anisotropic_signal = stick(b, g, d, theta, phi)\n",
        "  return S0*((1-f)*isotropic_signal + f*anisotropic_signal)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to check your function runs correctly, and outputs a vector of the expected size:"
      ],
      "metadata": {
        "id": "WZIdntY6ymwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vox_test = 0\n",
        "d = 1.7e-3\n",
        "\n",
        "result_test = ball_and_stick(theta=np.pi/2,\n",
        "                             phi=np.pi,\n",
        "                             f=0.5,\n",
        "                             d=d,\n",
        "                             S0 = S0[vox_test,:],\n",
        "                             b=b[non_b0idx],\n",
        "                             g=g[non_b0idx,:])\n",
        "\n",
        "print(result_test)\n",
        "print(result_test.shape)"
      ],
      "metadata": {
        "id": "bu0xUQYPygVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybV5TQjO2CHK"
      },
      "source": [
        "\n",
        "Now we want to fit the model to our data. We have our acquisition parameters `b` and `g`,  and measured values for `S0`. We can also fix `d` based on information from the literature. The parameters we want to optimise are: `theta`, `phi` and `f`.\n",
        "\n",
        "We'll be using scipy's non-linear least squares optimiser to fit the model. We have provided the code for this below. Take a look at the documentation to help you understand the inputs to the least_squares function: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html. The first input we need to provide is a function which computes the vector of residuals, with the signature `fun(x, *args, **kwargs)`. Here, `x` is the variable being optimized. Since the minimization is performed with respect to `x`, we need to combine `theta`, `phi`, and `f` as a single NumPy array (ndarray) and pass it as `x`.\n",
        "\n",
        "We have created a `residuals` function that calculates the difference between the measured signal `S` and the simulated signal from the `ball_and_stick` model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBgWjtnVZTkU"
      },
      "outputs": [],
      "source": [
        "def residuals(x, S0, d, b, g, S):\n",
        "  # x = (theta, phi, f)\n",
        "  r = ball_and_stick(x[0], x[1], x[2], d, S0, b, g) - S\n",
        "  return r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_YWvN0hr_rJ"
      },
      "source": [
        "We pass this function to the `least_squares` optimiser, which uses it to minimise the sum-of-squared error between the model and the data. Take some time to look through the code below to understand the different parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgAUKC52929o"
      },
      "outputs": [],
      "source": [
        "d = 1.7e-3 # diffusion constant, found empirically\n",
        "Nvox = np.shape(S0)[0]\n",
        "\n",
        "# set up empty arrays to store the parameter estimates for each voxel\n",
        "theta_estimates = np.zeros(Nvox)\n",
        "phi_estimates = np.zeros(Nvox)\n",
        "f_estimates = np.zeros(Nvox)\n",
        "\n",
        "# we will also store the sum-of-squared residuals in each voxel, to evaluate the model fit\n",
        "SSE = np.zeros(Nvox)\n",
        "\n",
        "for i in range(Nvox):\n",
        "  # we perform a least squares fit in each voxel\n",
        "  res = least_squares(residuals,\n",
        "              x0 = [np.pi/2, np.pi, 0.5], # initial guesses for theta, phi, f\n",
        "              args=(S0[i,:], d, b[non_b0idx], g[non_b0idx,:], S[i,:]), # additional arguments to pass to the sum_squared_error function\n",
        "              bounds =([0,0,0], [np.pi, 2*np.pi, 1]), # lower and upper bounds for theta, phi, f\n",
        "              ftol = 1e-9, xtol=1e-9) # tolerance values for termination\n",
        "\n",
        "  # We record voxel-wise estimates for theta, phi and f\n",
        "  # from the output of the least_squares function\n",
        "  theta, phi, f = res.x\n",
        "  theta_estimates[i] = theta\n",
        "  phi_estimates[i] = phi\n",
        "  f_estimates[i] = f\n",
        "\n",
        "  # we calculate the sum-of-squared errors from the residuals\n",
        "  SSE[i] = np.sum(res.fun**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQsrh4cb2W8m"
      },
      "source": [
        "This can take a few minutes.\n",
        "\n",
        "In the meantime, have a look at the extension tasks below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRMJCTi_3fzH"
      },
      "source": [
        "## Visualisation\n",
        "Once the least-squares fit has finished running, we can visualise our results.\n",
        "\n",
        "First, we can look at the directions of the \"stick\" component. We convert the `theta` and `phi` estimates into regular Cartesian coordinates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubQ5ggvha5QI"
      },
      "outputs": [],
      "source": [
        "# get the vectors in cartesian coordinates (x,y,z) for visualisation\n",
        "dirs = np.array([np.sin(theta_estimates)*np.cos(phi_estimates),\n",
        "                 np.sin(theta_estimates)*np.sin(phi_estimates),\n",
        "                 np.cos(theta_estimates)])\n",
        "\n",
        "dirs = dirs.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_PgJk6y-oBs"
      },
      "source": [
        "We visualise the sticks in the same was as we did with the principal directions from DTI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FaPFRSkalLy"
      },
      "outputs": [],
      "source": [
        "# Choose a slice in which you will visualise the principal direction\n",
        "slice_idx = np.where(idx[2]==1)\n",
        "\n",
        "# Considering only the x and y components, plot a quiver plot of the prinicpal\n",
        "# direction in each white matter voxel in this slice\n",
        "# see matplotlib.pyplot.quiver documentation:\n",
        "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.quiver.html\n",
        "\n",
        "# x and y correspond to location of each arrow,\n",
        "# i.e. the coordinates of the white matter voxel\n",
        "x = idx[0][slice_idx]\n",
        "y = idx[1][slice_idx]\n",
        "\n",
        "# u and v correspond to the x and y components of the principal direction in\n",
        "# each voxel\n",
        "u = dirs[slice_idx,0]\n",
        "v = dirs[slice_idx,1]\n",
        "\n",
        "fig = plt.figure\n",
        "plt.quiver(x,y,u,v, scale_units='x', scale=1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfY3Trf-zBx"
      },
      "source": [
        "Compare this output to the one from the previous exercise. Can you see any differences?\n",
        "\n",
        "Next, we can plot the volume fractions of the stick components, `f`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wonFxCDbkTe"
      },
      "outputs": [],
      "source": [
        "# plot the fiber volume fractions\n",
        "f_map = np.zeros_like(mask)\n",
        "f_map[idx[0],idx[1],idx[2]] = f_estimates\n",
        "\n",
        "plt.imshow(f_map[:,:,1].T, origin=\"lower\")\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0PwW7-C_twG"
      },
      "source": [
        "We can also look at the error between the model fit and the measured signal. We can this to compare these results with the models from the other exercises."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SSE_map = np.zeros_like(mask)\n",
        "SSE_map[idx[0],idx[1],idx[2]] = SSE\n",
        "\n",
        "plt.imshow(SSE_map[:,:,1].T, origin=\"lower\", vmax = 5000)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "print(f\"median sum-of-squared error = {np.median(SSE)}\")"
      ],
      "metadata": {
        "id": "NnBQMUT1_DOU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you notice about the areas with high error in the model fit?"
      ],
      "metadata": {
        "id": "zyRW5NpHAgdv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs3Y5irIscAr"
      },
      "source": [
        "# Extension tasks:\n",
        "\n",
        "*   What are the pros and cons of the ball and stick model?\n",
        "*   Can you adjust the parameters in the least_squares optimiser to improve the model fit?\n",
        "*   What other compartments could we add to improve the accuracy of the model? Can you implement them?\n",
        "*   Look at the different methods available in scipy.optimise. How would you use these to fit the parameters? (https://docs.scipy.org/doc/scipy/reference/optimize.html).\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}